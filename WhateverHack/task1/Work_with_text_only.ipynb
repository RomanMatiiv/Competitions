{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.sparse import csr_matrix,hstack\n",
    "\n",
    "PATH_TO_DATA=\"/notebooks/roman/task1/data/\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(pred,name=\"ans\"):\n",
    "    ans=pd.read_csv(PATH_TO_DATA+\"sample_submission.csv\")\n",
    "    ans[\"label\"]=pred\n",
    "    ans.to_csv(\"answers/\"+name+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План\n",
    "* tfidf\n",
    "* tfidf c ngram stop words etc\n",
    "* Count wectorizer\n",
    "* линейные модели\n",
    "* knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавить фичи\n",
    "* Добавить теги\n",
    "* Добавить дину подписи\n",
    "* Добавить длину подписи деленную на n (n подобрать)\n",
    "* Number of words\n",
    "* Number of characters\n",
    "* Average word length\n",
    "* Number of stopwords\n",
    "* Number of special characters\n",
    "* Number of numerics\n",
    "* Number of uppercase words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv(PATH_TO_DATA+\"train_data.csv\")\n",
    "data_test=pd.read_csv(PATH_TO_DATA+\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_NoImg=data_train.drop(\"image_name\",axis=1)\n",
    "data_test_NoImg=data_test.drop(\"image_name\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    128292\n",
       "1      8265\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_NoImg['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(data_train_NoImg,random_state=42,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "tfidf=TfidfVectorizer()\n",
    "train_tfidf=tfidf.fit_transform(train[\"text\"])\n",
    "test_tfidf=tfidf.transform(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr\n",
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(train_tfidf,train[\"label\"])\n",
    "\n",
    "predict=lr.predict_proba(test_tfidf)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6019956360477763"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test[\"label\"],predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf  stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "tfidf=TfidfVectorizer(stop_words=stop_words)\n",
    "train_tfidf=tfidf.fit_transform(train[\"text\"])\n",
    "test_tfidf=tfidf.transform(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr\n",
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(train_tfidf,train[\"label\"])\n",
    "\n",
    "predict=lr.predict_proba(test_tfidf)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5936288302634535"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test[\"label\"],predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ухудшило"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf c ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,2))\n",
    "train_tfidf=tfidf.fit_transform(train[\"text\"])\n",
    "test_tfidf=tfidf.transform(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr\n",
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(train_tfidf,train[\"label\"])\n",
    "\n",
    "predict=lr.predict_proba(test_tfidf)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6088818325159076"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test[\"label\"],predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "чутка улучшило"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lenth comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#lenth feature\n",
    "train[\"lenth\"]=train[\"text\"].apply(lambda x: len(x))\n",
    "test[\"lenth\"]=test[\"text\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(ngram_range=(1,2))\n",
    "train_tfidf=tfidf.fit_transform(train[\"text\"])\n",
    "test_tfidf=tfidf.transform(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=csr_matrix(train[\"lenth\"].values.reshape(len(train),-1))\n",
    "b=csr_matrix(test[\"lenth\"].values.reshape(len(test),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_leth=hstack((train_tfidf,a))\n",
    "test_tfidf_leth=hstack((test_tfidf,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(train_tfidf_leth,train[\"label\"])\n",
    "\n",
    "predict=lr.predict_proba(test_tfidf_leth)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6088777231969127"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test[\"label\"],predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "чутка улучшило"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenth feature\n",
    "train[\"lenth\"]=train[\"text\"].apply(lambda x: len(x))\n",
    "test[\"lenth\"]=test[\"text\"].apply(lambda x: len(x))\n",
    "\n",
    "a=csr_matrix(train[\"lenth\"].values.reshape(len(train),-1))\n",
    "b=csr_matrix(test[\"lenth\"].values.reshape(len(test),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(ngram_range=(1,2))\n",
    "train_tfidf=tfidf.fit_transform(train[\"text\"])\n",
    "test_tfidf=tfidf.transform(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "counVec=CountVectorizer(ngram_range=(1,2))\n",
    "train_counVec=counVec.fit_transform(train[\"text\"])\n",
    "test_counVec=counVec.transform(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_leth_CV=hstack((train_tfidf,train_counVec,a))\n",
    "test_tfidf_leth_CV=hstack((test_tfidf,test_counVec,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(train_tfidf_leth_CV,train[\"label\"])\n",
    "\n",
    "predict=lr.predict_proba(test_tfidf_leth_CV)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6005282787690971"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test[\"label\"],predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count_vect ухучшил модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engenering\n",
    "* Добавить теги done\n",
    "* Добавить дину подписи done\n",
    "* Добавить длину тега done\n",
    "* Number of words done\n",
    "* Average word length done\n",
    "* Number of stopwords done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка данных\n",
    "data_train=pd.read_csv(PATH_TO_DATA+\"train_data.csv\")\n",
    "data_test=pd.read_csv(PATH_TO_DATA+\"test_data.csv\")\n",
    "casts=pd.read_csv(PATH_TO_DATA+\"casts.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теги картинок\n",
    "imageTags={}\n",
    "for i in casts.values:\n",
    "    imageTags[i[0]]=i[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление столбца тегов картинки\n",
    "data_train[\"tags\"]=data_train[\"image_name\"].replace(imageTags)\n",
    "\n",
    "# Удаление номера картинки\n",
    "data_train_NoImg=data_train.drop(\"image_name\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приведение к нижнему регистру\n",
    "data_train_NoImg[\"text\"]=data_train_NoImg[\"text\"].apply(lambda x:x.lower())\n",
    "data_train_NoImg[\"tags\"]=data_train_NoImg[\"tags\"].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag  вопросительный и восклицательный знак\n",
    "data_train_NoImg[\"special character\"]=data_train_NoImg[\"text\"].apply(lambda x:int(any([i in [\"?\",\"!\"]for i in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаление згаков преинания\n",
    "data_train_NoImg[\"text\"]=data_train_NoImg[\"text\"].apply(lambda x:re.sub(r'[^\\w\\s]','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавить дину подписи\n",
    "# Добавить длину тега\n",
    "data_train_NoImg[\"lenth_text\"]=data_train_NoImg[\"text\"].apply(lambda x: len(x))\n",
    "data_train_NoImg[\"lenth_tags\"]=data_train_NoImg[\"tags\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words\n",
    "data_train_NoImg[\"num_w_text\"]=data_train_NoImg[\"text\"].apply(lambda x: len(x.split(\" \")))\n",
    "data_train_NoImg[\"num_w_tags\"]=data_train_NoImg[\"tags\"].apply(lambda x: len(x.split(\":\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average word length\n",
    "data_train_NoImg[\"average_w_lenth\"]=data_train_NoImg[\"text\"].apply(lambda x: np.mean([len(i) for i in x.split(\" \")]))\n",
    "data_train_NoImg[\"average_tag_lenth\"]=data_train_NoImg[\"tags\"].apply(lambda x: np.mean([len(i) for i in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "data_train_NoImg[\"num_stop_w\"]=data_train_NoImg[\"text\"].apply(lambda x: sum([int(w in stop) for w in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spelling correction (минут 40 считалось)\n",
    "data_train_NoImg[\"corrected_text\"]=data_train_NoImg[\"text\"].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flag была ли ошибка (минут 15)\n",
    "data_train_NoImg[\"error_in_text\"]=data_train_NoImg[\"corrected_text\"].apply(lambda x: int(x in data_train_NoImg[\"text\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обработка тегов\n",
    "data_train_NoImg[\"tags_new\"]=data_train_NoImg[\"tags\"].apply(lambda x:\" \".join(x.replace(\" \",\"_\").split(\":,\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "\n",
    "data_train_NoImg[\"stemm_text\"]=data_train_NoImg[\"text\"].apply(lambda x: \" \".join([st.stem(i) for i in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "from textblob import Word\n",
    "data_train_NoImg[\"lemm_text\"]=data_train_NoImg[\"text\"].apply(lambda x: \" \".join([Word(i).lemmatize() for i in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>special character</th>\n",
       "      <th>lenth_text</th>\n",
       "      <th>lenth_tags</th>\n",
       "      <th>num_w_text</th>\n",
       "      <th>num_w_tags</th>\n",
       "      <th>average_w_lenth</th>\n",
       "      <th>average_tag_lenth</th>\n",
       "      <th>num_stop_w</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>error_in_text</th>\n",
       "      <th>tags_new</th>\n",
       "      <th>stemm_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>mom but thats a letter</td>\n",
       "      <td>facial expression:,emotion:,smile:,event:,chri...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>25.5</td>\n",
       "      <td>2</td>\n",
       "      <td>mon but that a letter</td>\n",
       "      <td>0</td>\n",
       "      <td>facial_expression emotion smile event christmas:</td>\n",
       "      <td>mom but that a letter</td>\n",
       "      <td>mom but thats a letter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        text  \\\n",
       "9091  mom but thats a letter   \n",
       "\n",
       "                                                   tags  special character  \\\n",
       "9091  facial expression:,emotion:,smile:,event:,chri...                  0   \n",
       "\n",
       "      lenth_text  lenth_tags  num_w_text  num_w_tags  average_w_lenth  \\\n",
       "9091          22          52           5           6              3.6   \n",
       "\n",
       "      average_tag_lenth  num_stop_w         corrected_text  error_in_text  \\\n",
       "9091               25.5           2  mon but that a letter              0   \n",
       "\n",
       "                                              tags_new             stemm_text  \\\n",
       "9091  facial_expression emotion smile event christmas:  mom but that a letter   \n",
       "\n",
       "                   lemm_text  \n",
       "9091  mom but thats a letter  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test, y_train, y_test=train_test_split(data_train_NoImg.drop(\"label\",axis=1),data_train_NoImg[\"label\"],random_state=42,test_size=0.3)\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix,hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default    text and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "text_tfidf_train=tfidf.fit_transform(train[\"text\"])\n",
    "text_tfidf_test=tfidf.transform(test[\"text\"])\n",
    "\n",
    "tags_tfidf_train=tfidf.fit_transform(train[\"tags\"])\n",
    "tags_tfidf_test=tfidf.transform(test[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_str=[\"special character\",\"lenth_text\",\"lenth_tags\",\n",
    "          \"num_w_text\",\"num_w_tags\",\"average_w_lenth\",\n",
    "          \"average_tag_lenth\",\"num_stop_w\",\"error_in_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Численные признаки в разряженный вид\n",
    "train_num_csr=csr_matrix(train[not_str].values.reshape(len(train),-1))\n",
    "test_num_csr=csr_matrix(test[not_str].values.reshape(len(test),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обьеденение\n",
    "train_csr=hstack((text_tfidf_train,tags_tfidf_train,train_num_csr))\n",
    "test_csr=hstack((text_tfidf_test,tags_tfidf_test,test_num_csr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7286983563787488"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(train_csr,y_train)\n",
    "predict=lr.predict_proba(test_csr)[:,1]\n",
    "roc_auc_score(y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correct_text and tags_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "text_tfidf_train=tfidf.fit_transform(train[\"corrected_text\"])\n",
    "text_tfidf_test=tfidf.transform(test[\"corrected_text\"])\n",
    "\n",
    "tags_tfidf_train=tfidf.fit_transform(train[\"tags_new\"])\n",
    "tags_tfidf_test=tfidf.transform(test[\"tags_new\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Численные признаки в разряженный вид\n",
    "train_num_csr=csr_matrix(train[not_str].values.reshape(len(train),-1))\n",
    "test_num_csr=csr_matrix(test[not_str].values.reshape(len(test),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обьеденение\n",
    "train_csr=hstack((text_tfidf_train,tags_tfidf_train,train_num_csr))\n",
    "test_csr=hstack((text_tfidf_test,tags_tfidf_test,test_num_csr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7309938756588836"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(train_csr,y_train)\n",
    "predict=lr.predict_proba(test_csr)[:,1]\n",
    "roc_auc_score(y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correct_text and tags_new stemm lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# text_tfidf_train=tfidf.fit_transform(train[\"corrected_text\"])\n",
    "# text_tfidf_test=tfidf.transform(test[\"corrected_text\"])\n",
    "\n",
    "tags_tfidf_train=tfidf.fit_transform(train[\"tags_new\"])\n",
    "tags_tfidf_test=tfidf.transform(test[\"tags_new\"])\n",
    "\n",
    "# stem_tfidf_train=tfidf.fit_transform(train[\"stemm_text\"])\n",
    "# stem_tfidf_test=tfidf.transform(test[\"stemm_text\"])\n",
    "\n",
    "lem_tfidf_train=tfidf.fit_transform(train[\"lemm_text\"])\n",
    "lem_tfidf_test=tfidf.transform(test[\"lemm_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Численные признаки в разряженный вид\n",
    "train_num_csr=csr_matrix(train[not_str].values.reshape(len(train),-1))\n",
    "test_num_csr=csr_matrix(test[not_str].values.reshape(len(test),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обьеденение\n",
    "# train_csr=hstack((text_tfidf_train,tags_tfidf_train,train_num_csr,stem_tfidf_train,lem_tfidf_train))\n",
    "# test_csr=hstack((text_tfidf_test,tags_tfidf_test,test_num_csr,stem_tfidf_test,lem_tfidf_test))\n",
    "\n",
    "train_csr=hstack((tags_tfidf_train,train_num_csr,lem_tfidf_train))\n",
    "test_csr=hstack((tags_tfidf_test,test_num_csr,lem_tfidf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7312916360872588"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(train_csr,y_train)\n",
    "predict=lr.predict_proba(test_csr)[:,1]\n",
    "roc_auc_score(y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление столбца тегов картинки\n",
    "data_test[\"tags\"]=data_test[\"image_name\"].replace(imageTags)\n",
    "\n",
    "# Удаление номера картинки\n",
    "data_test_NoImg=data_test.drop(\"image_name\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приведение к нижнему регистру\n",
    "data_test_NoImg[\"text\"]=data_test_NoImg[\"text\"].apply(lambda x:x.lower())\n",
    "data_test_NoImg[\"tags\"]=data_test_NoImg[\"tags\"].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag  вопросительный и восклицательный знак\n",
    "data_test_NoImg[\"special character\"]=data_test_NoImg[\"text\"].apply(lambda x:int(any([i in [\"?\",\"!\"]for i in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаление згаков преинания\n",
    "data_test_NoImg[\"text\"]=data_test_NoImg[\"text\"].apply(lambda x:re.sub(r'[^\\w\\s]','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавить дину подписи\n",
    "# Добавить длину тега\n",
    "data_test_NoImg[\"lenth_text\"]=data_test_NoImg[\"text\"].apply(lambda x: len(x))\n",
    "data_test_NoImg[\"lenth_tags\"]=data_test_NoImg[\"tags\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words\n",
    "data_test_NoImg[\"num_w_text\"]=data_test_NoImg[\"text\"].apply(lambda x: len(x.split(\" \")))\n",
    "data_test_NoImg[\"num_w_tags\"]=data_test_NoImg[\"tags\"].apply(lambda x: len(x.split(\":\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average word length\n",
    "data_test_NoImg[\"average_w_lenth\"]=data_test_NoImg[\"text\"].apply(lambda x: np.mean([len(i) for i in x.split(\" \")]))\n",
    "data_test_NoImg[\"average_tag_lenth\"]=data_test_NoImg[\"tags\"].apply(lambda x: np.mean([len(i) for i in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data_test_NoImg[\"num_stop_w\"]=data_test_NoImg[\"text\"].apply(lambda x: sum([int(w in stop) for w in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spelling correction\n",
    "data_test_NoImg[\"corrected_text\"]=data_test_NoImg[\"text\"].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flag была ли ошибка\n",
    "data_test_NoImg[\"error_in_text\"]=data_test_NoImg[\"corrected_text\"].apply(lambda x: int(x in data_test_NoImg[\"text\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обработка тегов\n",
    "data_test_NoImg[\"tags_new\"]=data_test_NoImg[\"tags\"].apply(lambda x:\" \".join(x.replace(\" \",\"_\").split(\":,\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "\n",
    "data_test_NoImg[\"stemm_text\"]=data_test_NoImg[\"text\"].apply(lambda x: \" \".join([st.stem(i) for i in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "from textblob import Word\n",
    "data_test_NoImg[\"lemm_text\"]=data_test_NoImg[\"text\"].apply(lambda x: \" \".join([Word(i).lemmatize() for i in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creat final model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data_train_NoImg.drop(\"label\",axis=1)\n",
    "y=data_train_NoImg[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=data_test_NoImg.drop(\"id\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "tags_tfidf_train=tfidf.fit_transform(X_train[\"tags_new\"])\n",
    "tags_tfidf_test=tfidf.transform(X_test[\"tags_new\"])\n",
    "\n",
    "\n",
    "lem_tfidf_train=tfidf.fit_transform(X_train[\"lemm_text\"])\n",
    "lem_tfidf_test=tfidf.transform(X_test[\"lemm_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Численные признаки в разряженный вид\n",
    "train_num_csr=csr_matrix(X_train[not_str])\n",
    "test_num_csr=csr_matrix(X_test[not_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обьеденение\n",
    "train_csr=hstack((tags_tfidf_train,train_num_csr,lem_tfidf_train))\n",
    "test_csr=hstack((tags_tfidf_test,test_num_csr,lem_tfidf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(train_csr,y)\n",
    "predict=lr.predict_proba(test_csr)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(predict,\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
